{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMVJWx/zG8AD8lhVx7+ZKZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedshoaib14/Chennai-Geocoding-TB-data-/blob/main/Chennai_TB_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install packages\n",
        "!pip install libpysal esda\n",
        "!pip install pandas geopandas shapely scikit-learn folium"
      ],
      "metadata": {
        "id": "BUnjdlNpZXg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title geocoding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from libpysal.weights import DistanceBand\n",
        "from esda.getisord import G_Local\n",
        "import folium\n",
        "\n",
        "# 1. Load the geocoded sheet\n",
        "xl = pd.ExcelFile('chennai TB data.xlsx')\n",
        "df = xl.parse('india_geo_coding_address_lat_an')\n",
        "\n",
        "# 2. Strip whitespace and detect lat/lon columns (case-insensitive)\n",
        "df.columns = df.columns.str.strip()\n",
        "lat_cols = [c for c in df.columns if c.lower() == 'latitude']\n",
        "lon_cols = [c for c in df.columns if c.lower() == 'longitude']\n",
        "\n",
        "if not lat_cols or not lon_cols:\n",
        "    raise KeyError(f\"Latitude/Longitude columns not found. Available columns: {df.columns.tolist()}\")\n",
        "\n",
        "lat_col = lat_cols[0]\n",
        "lon_col = lon_cols[0]\n",
        "\n",
        "print(f\"Using latitude column: '{lat_col}', longitude column: '{lon_col}'\")\n",
        "\n",
        "# 3. Convert to GeoDataFrame (WGS84)\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    df,\n",
        "    geometry=gpd.points_from_xy(df[lon_col], df[lat_col]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# 4. Project to UTM zone 43N (meters)\n",
        "gdf = gdf.to_crs(epsg=32643)\n",
        "coords = np.vstack([gdf.geometry.x, gdf.geometry.y]).T\n",
        "\n",
        "# 5. Compute KDE density (1 km bandwidth)\n",
        "kde = KernelDensity(bandwidth=1000, kernel='gaussian')\n",
        "kde.fit(coords)\n",
        "gdf['kde_density'] = np.exp(kde.score_samples(coords))\n",
        "\n",
        "# 6. Build spatial weights (2 km threshold)\n",
        "w = DistanceBand.from_dataframe(gdf, threshold=2000, silence_warnings=True)\n",
        "\n",
        "# 7. Compute Local Getis-Ord Gi*\n",
        "g_local = G_Local(gdf['kde_density'], w, transform='B')\n",
        "gdf['GiZ'] = g_local.Zs\n",
        "gdf['GiP'] = g_local.p_sim\n",
        "\n",
        "# 8. Classify Gi* results\n",
        "def classify_gistar(z):\n",
        "    if z > 1.96:\n",
        "        return 'hot_spot'\n",
        "    elif z < -1.96:\n",
        "        return 'cold_spot'\n",
        "    else:\n",
        "        return 'non_significant'\n",
        "\n",
        "gdf['Gi_star'] = gdf['GiZ'].apply(classify_gistar)\n",
        "\n",
        "# 9. Create and save Folium map\n",
        "map_path = \"kde_gistar_map.html\"\n",
        "center = [df[lat_col].mean(), df[lon_col].mean()]\n",
        "m = folium.Map(location=center, zoom_start=12, tiles='CartoDB.Positron')\n",
        "colors = {'hot_spot': 'red', 'cold_spot': 'blue', 'non_significant': 'gray'}\n",
        "\n",
        "for _, row in gdf.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row[lat_col], row[lon_col]],\n",
        "        radius=4,\n",
        "        color=colors[row['Gi_star']],\n",
        "        fill=True,\n",
        "        fill_opacity=0.7,\n",
        "        popup=(\n",
        "            f\"<b>KDE density:</b> {row['kde_density']:.2f}<br>\"\n",
        "            f\"<b>Gi* Z-score:</b> {row['GiZ']:.2f}<br>\"\n",
        "            f\"<b>Gi* p-value:</b> {row['GiP']:.3f}<br>\"\n",
        "            f\"<b>Classification:</b> {row['Gi_star']}\"\n",
        "        )\n",
        "    ).add_to(m)\n",
        "\n",
        "\n",
        "legend_html = '''\n",
        "<div style=\"\n",
        "     position: fixed;\n",
        "     bottom: 50px; left: 50px; max-width: 360px;\n",
        "     z-index:9999; font-size:14px; line-height: 1.5;\n",
        "     background-color: rgba(255,255,255,0.95);\n",
        "     padding: 12px 15px; border: 2px solid gray;\n",
        "     border-radius: 10px;\n",
        "     box-shadow: 0 0 8px rgba(0,0,0,0.3);\n",
        "     word-wrap: break-word;\n",
        "     overflow-wrap: break-word;\">\n",
        "<b>Z-Score & P-Value</b><br><br>\n",
        "<b>Z-Score:</b><br>\n",
        "<span style=\"color:red;\">Z &gt; 1.96</span>: Hotspot (95%+ confidence)<br>\n",
        "<span style=\"color:blue;\">Z &lt; -1.96</span>: Coldspot (95%+ confidence)<br>\n",
        "-1.96 ≤ Z ≤ 1.96: Not significant<br><br>\n",
        "<b>P-Value:</b><br>\n",
        "p &lt; 0.01 → Very strong evidence<br>\n",
        "p &lt; 0.05 → Statistically significant<br>\n",
        "p ≥ 0.05 → Not significant\n",
        "</div>\n",
        "'''\n",
        "\n",
        "\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "m.save(map_path)\n",
        "print(f\"Interactive KDE + Gi* hotspot map saved to {map_path}\")\n",
        "\n",
        "\n",
        "\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "out_path = 'kde_gistar_map new .html'\n",
        "m.save(out_path)\n",
        "print(f\"Map saved to {out_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "SjGMLkbRMhEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "from IPython.display import display\n",
        "\n",
        "# Load geocoded data\n",
        "df = pd.read_excel('/content/chennai TB data.xlsx', sheet_name='india_geo_coding_address_lat_an')\n",
        "\n",
        "# Define metrics and their column names\n",
        "metrics = {\n",
        "    'Infected rate': 'Infected rate',\n",
        "    'Density Per Km2': 'Density Per Km2'\n",
        "}\n",
        "\n",
        "# Initialize summary storage\n",
        "summary_rows = []\n",
        "\n",
        "# Create and save maps for each metric\n",
        "map_paths = {}\n",
        "\n",
        "for name, col in metrics.items():\n",
        "    # Compute quartiles\n",
        "    q25, q75 = df[col].quantile([0.25, 0.75])\n",
        "\n",
        "    # Classify spots\n",
        "    spot_col = f'spot_{col.replace(\" \", \"_\").lower()}'\n",
        "    df[spot_col] = df[col].apply(\n",
        "        lambda v: 'cold' if v < q25 else ('hot' if v > q75 else 'intermediate'))\n",
        "\n",
        "    # Summarize counts\n",
        "    counts = df[spot_col].value_counts()\n",
        "    summary_rows.append({\n",
        "        'metric': name,\n",
        "        'cold count': counts.get('cold', 0),\n",
        "        'intermediate count': counts.get('intermediate', 0),\n",
        "        'hot count': counts.get('hot', 0)\n",
        "    })\n",
        "\n",
        "from folium.plugins import MarkerCluster\n",
        "\n",
        "# Create Folium map\n",
        "center = [df['Latitude'].mean(), df['Longitude'].mean()]\n",
        "m = folium.Map(location=center, zoom_start=12)\n",
        "colors = {'cold': 'blue', 'intermediate': 'orange', 'hot': 'red'}\n",
        "\n",
        "# Add marker cluster\n",
        "marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    tooltip_text = (\n",
        "        f\"<b>Area:</b> {row['Area']}<br>\"\n",
        "        f\"<b>Pin Code:</b> {row['Pin Code']}<br>\"\n",
        "        f\"<b>Infected rate:</b> {row['Infected rate']}<br>\"\n",
        "        f\"<b>Density Per Km²:</b> {row['Density Per Km2']}\"\n",
        "    )\n",
        "\n",
        "    folium.CircleMarker(\n",
        "        location=[row['Latitude'], row['Longitude']],\n",
        "        radius=5,\n",
        "        color=colors[row[spot_col]],\n",
        "        fill=True,\n",
        "        fill_opacity=0.8,\n",
        "        tooltip=folium.Tooltip(tooltip_text, sticky=True)\n",
        "    ).add_to(marker_cluster)\n",
        "\n",
        "# Save map\n",
        "path = '/content/infected rate and densty _map.html'\n",
        "m.save(path)\n",
        "map_paths[name] = path\n",
        "\n",
        "# Display summary table\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "print(\"Classification Summary by Metric\")\n",
        "display(summary_df)\n",
        "\n",
        "# Print map locations\n",
        "print(\"\\nMaps saved at:\")\n",
        "for metric, path in map_paths.items():\n",
        "    print(f\"- {metric}: {path}\")\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Gc6e6v6N_xw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_excel('/content/chennai TB data.xlsx', sheet_name='india_geo_coding_address_lat_an')\n",
        "\n",
        "# Show the actual column names\n",
        "print(\"Column names in the Excel sheet:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "PrCRYDZ9TBPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title cold count\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "summary_df['cold count'].plot(kind='hist', bins=20, title='cold count')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "LFfvr9TDHaVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from IPython.display import display\n",
        "\n",
        "# Load geocoded data\n",
        "df = pd.read_excel('/content/chennai TB data.xlsx', sheet_name='india_geo_coding_address_lat_an')\n",
        "\n",
        "# Define metrics and their column names\n",
        "metrics = {\n",
        "    'Infected rate': 'Infected rate',\n",
        "    'Density Per Km2': 'Density Per Km2'\n",
        "}\n",
        "\n",
        "# Initialize summary storage\n",
        "summary_rows = []\n",
        "\n",
        "# Create and save maps for each metric\n",
        "map_paths = {}\n",
        "\n",
        "for name, col in metrics.items():\n",
        "    # Compute quartiles\n",
        "    q25, q75 = df[col].quantile([0.25, 0.75])\n",
        "\n",
        "    # Classify spots\n",
        "    spot_col = f'spot_{col.replace(\" \", \"_\").lower()}'\n",
        "    df[spot_col] = df[col].apply(\n",
        "        lambda v: 'cold' if v < q25 else ('hot' if v > q75 else 'intermediate'))\n",
        "\n",
        "    # Summarize counts\n",
        "    counts = df[spot_col].value_counts()\n",
        "    summary_rows.append({\n",
        "        'metric': name,\n",
        "        'cold count': counts.get('cold', 0),\n",
        "        'intermediate count': counts.get('intermediate', 0),\n",
        "        'hot count': counts.get('hot', 0)\n",
        "    })\n",
        "\n",
        "    # Create Folium map\n",
        "    center = [df['Latitude'].mean(), df['Longitude'].mean()]\n",
        "    m = folium.Map(location=center, zoom_start=12)\n",
        "    colors = {'cold': 'blue', 'intermediate': 'orange', 'hot': 'red'}\n",
        "\n",
        "    # Add marker cluster\n",
        "    marker_cluster = MarkerCluster().add_to(m)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        classification = row[spot_col].capitalize() + \" Spot\"\n",
        "        tooltip_text = (\n",
        "            f\"<b>Area:</b> {row['Area']}<br>\"\n",
        "            f\"<b>Pin Code:</b> {row['Pin Code']}<br>\"\n",
        "            f\"<b>Infected rate:</b> {row['Infected rate']}<br>\"\n",
        "            f\"<b>Density Per Km²:</b> {row['Density Per Km2']}<br>\"\n",
        "            f\"<b>Classification:</b> {classification}\"\n",
        "        )\n",
        "\n",
        "        folium.CircleMarker(\n",
        "            location=[row['Latitude'], row['Longitude']],\n",
        "            radius=5,\n",
        "            color=colors[row[spot_col]],\n",
        "            fill=True,\n",
        "            fill_opacity=0.8,\n",
        "            tooltip=folium.Tooltip(tooltip_text, sticky=True)\n",
        "        ).add_to(marker_cluster)\n",
        "\n",
        "        folium.CircleMarker(\n",
        "            location=[row['Latitude'], row['Longitude']],\n",
        "            radius=5,\n",
        "            color=colors[row[spot_col]],\n",
        "            fill=True,\n",
        "            fill_opacity=0.8,\n",
        "            tooltip=folium.Tooltip(tooltip_text, sticky=True)\n",
        "        ).add_to(marker_cluster)\n",
        "\n",
        "    # Add legend for color coding\n",
        "    legend_html = \"\"\"\n",
        "    <div style=\"position: fixed;\n",
        "                bottom: 50px; left: 50px; width: 150px; height: 100px;\n",
        "                border:2px solid grey; background-color: white; z-index:9999; font-size:12px;\n",
        "                padding: 10px;\">\n",
        "                <b></b><br>\n",
        "                <i style=\"background:blue; width: 20px; height: 20px; float:left; margin-right:10px;\"></i>Cold<br>\n",
        "                <i style=\"background:orange; width: 20px; height: 20px; float:left; margin-right:10px;\"></i>Intermediate<br>\n",
        "                <i style=\"background:red; width: 20px; height: 20px; float:left; margin-right:10px;\"></i>Hot<br>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "    # Save map\n",
        "    path = f'/content/_map.html'\n",
        "    m.save(path)\n",
        "    map_paths[name] = path\n",
        "\n",
        "# Display summary table\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "print(\"Classification Summary by Metric\")\n",
        "display(summary_df)\n",
        "\n",
        "# Print map locations\n",
        "print(\"\\nMaps saved at:\")\n",
        "for metric, path in map_paths.items():\n",
        "    print(f\"- {metric}: {path}\")\n"
      ],
      "metadata": {
        "id": "Fnc6khlZID90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zgEwKY_-ANi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Aimodel\n",
        "!pip install libpysal esda\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from libpysal.weights import DistanceBand\n",
        "from esda.getisord import G_Local\n",
        "\n",
        "# 1. Load and prepare geocoded TB data\n",
        "xl = pd.ExcelFile('chennai TB data.xlsx')\n",
        "df = xl.parse('india_geo_coding_address_lat_an')\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Identify coordinate columns\n",
        "tmp = df.copy()\n",
        "lat_col = [c for c in tmp.columns if c.lower() == 'latitude'][0]\n",
        "lon_col = [c for c in tmp.columns if c.lower() == 'longitude'][0]\n",
        "\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    tmp,\n",
        "    geometry=gpd.points_from_xy(tmp[lon_col], tmp[lat_col]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "# Project to metric CRS for distance-based features\n",
        "gdf = gdf.to_crs(epsg=32643)\n",
        "coords = np.vstack([gdf.geometry.x, gdf.geometry.y]).T\n",
        "\n",
        "# 2. Compute KDE density (bandwidth in meters)\n",
        "kde = KernelDensity(bandwidth=1000, kernel='gaussian')\n",
        "kde.fit(coords)\n",
        "gdf['kde_density'] = np.exp(kde.score_samples(coords))\n",
        "\n",
        "# 3. Build spatial weights and compute Local Getis-Ord Gi*\n",
        "w = DistanceBand.from_dataframe(gdf, threshold=2000, silence_warnings=True)\n",
        "g_local = G_Local(gdf['kde_density'], w, transform='B')\n",
        "gdf['GiZ'] = g_local.Zs\n",
        "gdf['Gi_star'] = gdf['GiZ'].apply(lambda z: 'hot_spot' if z > 1.96 else ('cold_spot' if z < -1.96 else 'non_significant'))\n",
        "\n",
        "# 4. Prepare features and target for classification\n",
        "gdf['x'] = gdf.geometry.x\n",
        "gdf['y'] = gdf.geometry.y\n",
        "feature_cols = ['x', 'y', 'kde_density']\n",
        "X = gdf[feature_cols]\n",
        "y = (gdf['Gi_star'] == 'hot_spot').astype(int)\n",
        "\n",
        "# 5. Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 6. Build preprocessing + model pipeline\n",
        "numeric_transformer = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transformer, feature_cols)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# 7. Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 10, 20]\n",
        "}\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "\n",
        "# 8. Evaluate on test set\n",
        "y_pred = grid.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 9. Save the trained pipeline\n",
        "model_path = 'tb_hotspot_classifier.pkl'\n",
        "joblib.dump(grid.best_estimator_, model_path)\n",
        "print(f\"Trained model saved to {model_path}\")\n"
      ],
      "metadata": {
        "id": "kR9hP97NqC92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import joblib\n",
        "import folium\n",
        "\n",
        "# 1. Load the trained model\n",
        "model = joblib.load('/content/tb_hotspot_classifier.pkl')\n",
        "\n",
        "# 2. Load and prepare new TB data (geocoded)\n",
        "xl = pd.ExcelFile('/content/chennai TB data.xlsx')\n",
        "df = xl.parse('india_geo_coding_address_lat_an')\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Identify lat/lon columns\n",
        "tmp = df.copy()\n",
        "lat_col = [c for c in tmp.columns if c.lower() == 'latitude'][0]\n",
        "lon_col = [c for c in tmp.columns if c.lower() == 'longitude'][0]\n",
        "\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    tmp,\n",
        "    geometry=gpd.points_from_xy(tmp[lon_col], tmp[lat_col]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "# Project to metric CRS matching training\n",
        "gdf = gdf.to_crs(epsg=32643)\n",
        "# Extract features: x, y, and compute KDE density\n",
        "coords = np.vstack([gdf.geometry.x, gdf.geometry.y]).T\n",
        "from sklearn.neighbors import KernelDensity\n",
        "kde = KernelDensity(bandwidth=1000, kernel='gaussian')\n",
        "kde.fit(coords)\n",
        "gdf['kde_density'] = np.exp(kde.score_samples(coords))\n",
        "gdf['x'] = gdf.geometry.x\n",
        "gdf['y'] = gdf.geometry.y\n",
        "\n",
        "# 3. Prepare feature matrix\n",
        "feature_cols = ['x', 'y', 'kde_density']\n",
        "X_new = gdf[feature_cols]\n",
        "\n",
        "# 4. Predict hotspot probability and class\n",
        "gdf['hotspot_prob'] = model.predict_proba(X_new)[:, 1]\n",
        "gdf['hotspot_pred'] = model.predict(X_new).astype(int)\n",
        "\n",
        "gdf['hotspot_label'] = gdf['hotspot_pred'].map({1: 'hot_spot', 0: 'non_hotspot'})\n",
        "\n",
        "# 5. Create Folium map showing predicted hotspots\n",
        "center = [df[lat_col].mean(), df[lon_col].mean()]\n",
        "m = folium.Map(location=center, zoom_start=12, tiles='CartoDB.Positron')\n",
        "colors = {'hot_spot': 'red', 'non_hotspot': 'blue'}\n",
        "\n",
        "for _, row in gdf.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row[lat_col], row[lon_col]],\n",
        "        radius=5,\n",
        "        color=colors[row['hotspot_label']],\n",
        "        fill=True,\n",
        "        fill_opacity=0.6,\n",
        "        popup=(\n",
        "            f\"<b>Probability:</b> {row['hotspot_prob']:.2f}<br>\"\n",
        "            f\"<b>Prediction:</b> {row['hotspot_label']}\"\n",
        "        )\n",
        "    ).add_to(m)\n",
        "\n",
        "# Save map\n",
        "out_map = 'tb_hotspot_predictions_map.html'\n",
        "m.save(out_map)\n",
        "print(f\"Prediction map saved to {out_map}\")\n"
      ],
      "metadata": {
        "id": "xtue9AH-rVc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}